import torch
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import numpy as np
from random import shuffle
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from utilities import * 
from EnronDataset import EnronLoader,EnronBatchLoader
from LSTM import ClassifierLSTM
from LogisticRegression import ClassifierLogisticRegression
import random

###  To prevent different results on each run due to random generators 

# this will seed torch's RNG for the main process, 
# each worker will have its torch seed set to base_seed + worker_id, where base_seed is a long generated by main process using its RNG.
#http://pytorch.org/docs/master/data.html
seed = 0
torch.manual_seed(seed)
# Setting Python RNG seed
random.seed(seed)
# Setting numpy seed for main and worker processes
numPySeed = torch.initial_seed() % (2^32)
np.random.seed(numPySeed)
#https://github.com/pytorch/pytorch/pull/2893
#torch.backends.cudnn.deterministic = True

##### path to spam and ham folder  

ham_dataPath = 'data/ham/'#'/home/sina/Downloads/enron/splitted/ham/'#'data/ham/'
spam_dataPath = 'data/spam/'#'/home/sina/Downloads/enron/splitted/spam/'#'data/spam/'
BoW_size =  512 	# the number of words used in bag of words which is used as features for : naive bayes, k-nn, decision tree and logistic regresion classifiers

##### Loading and preprocessing the data 

dataLoader = EnronLoader(hamDir=ham_dataPath,spamDir=spam_dataPath)
print("number of spam files: %d" % len(dataLoader.spamFiles))
print("number of ham files: %d" % len(dataLoader.hamFiles))

contentList_spam = dataLoader.readSpam()
contentList_ham = dataLoader.readHam()

##### Concatenating list of contents to a single string for further analysis 
allContent_spam = " ".join([content for content in contentList_spam])
allContent_ham  = " ".join([content for content in contentList_ham])

##### Concatenating contents of spam and ham   
allContent =  allContent_ham + allContent_spam
contentList = contentList_ham + contentList_spam 
numOfSamples = len(contentList)

##### Labels : "1" for Spam, and "0" for Ham 
lableList = [0]*len(contentList_ham) + [1]*len(contentList_spam)


##### Shuffling data and labels 
index_shuffle = list(range(numOfSamples))
shuffle(index_shuffle)
contentList_shuffled = []
lableList_shuffled = []

for i in index_shuffle:
	contentList_shuffled += [contentList[i]]
	lableList_shuffled += [lableList[i]]

contentList = contentList_shuffled
lableList = lableList_shuffled


##### Extracting vocabulary : 
##### ExtractVocab() returns a dictionary in which keys are words and values are words count
vocab_spam = extractVocab(allContent_spam)
vocab_ham  = extractVocab(allContent_ham)
vocal_all  = extractVocab(allContent)

numAllWordsInSpam = len(allContent_spam.split())
numAllWordsInHam = len(allContent_ham.split())

print("number of words in spam:%d and ham:%d" % (numAllWordsInSpam,numAllWordsInHam))


##### Sorting words based on their counts
##### wordCount() return two lists which are words and their count sorted form most common words to least
wordSorted_spam, wordSortedCounts_spam  = wordCount(vocab_spam)
wordSorted_ham , wordSortedCounts_ham   = wordCount(vocab_ham)
wordSorted , wordSortedCounts   = wordCount(vocal_all)

#### Visualization for words in spam and ham E-mails
'''
wordcloud = WordCloud().generate(allContent_spam)
plt.imshow(wordcloud, interpolation='bilinear')
plt.title("words in spam")
plt.show()

wordcloud = WordCloud().generate(allContent_ham)
plt.imshow(wordcloud, interpolation='bilinear')
plt.title("words in ham")
plt.show()

plt.plot(wordSorted[:100],wordSortedCounts[:100])
plt.title("100 most common words")
plt.xticks(rotation='vertical')
plt.show()
'''
##### To get a unique list of words we use sets
set_hamWords = set(wordSorted_ham)
set_spamWords = set(wordSorted_spam)
set_BagOfWords = set(wordSorted[:BoW_size])

##### Words from our vocab that are only in spam E-mails not ham (distinctive words)
VocabWordsOnlyInSpam = (set_BagOfWords & set_spamWords) - (set_BagOfWords & set_hamWords)

##### Words from our vocab that are only in ham e-mails not spam (distinctive words)

VocabWordsOnlyInHam = (set_BagOfWords & set_hamWords) - (set_BagOfWords & set_spamWords)

print("intersection of bag of words with spam words excluding ham words : %d" % len(VocabWordsOnlyInSpam))
print("intersection of bag of words with ham words excluding spam words : %d" % len(VocabWordsOnlyInHam))
print("*"*5 + "bag of words not included in ham files:")
print((set_BagOfWords & set_spamWords) - (set_BagOfWords & set_hamWords))
print("*"*5 + "bag of words not included in spam files:")
print((set_BagOfWords & set_hamWords) - (set_BagOfWords & set_spamWords))

##### Here we print the words in our vocabulary with thier occurrence counts in spam/ham content 
print("words in bag ")
for i in range(BoW_size):
	vocabWord = wordSorted[i]
	probWordInSpam = vocab_spam.get(vocabWord,0)
	probWordInHam = vocab_ham.get(vocabWord,0)
	print("%10s\tSpam : %6d\tHam : %6d" %(vocabWord,probWordInSpam,probWordInHam))

##### Defining training (50%) validation (25%) and test set (25%) length

trainLength = int(0.5 * numOfSamples)
valLength   = int(0.25 * numOfSamples)
testLength  = numOfSamples - (trainLength + valLength)
print("total number of samples %d splitted to %d training samples and %d test samples" % (numOfSamples,trainLength,testLength))


# Here we define the words to be used as features
# we a number of most common words , it can be thought as bags of words 
mostCommonWords = wordSorted[:BoW_size]

# Defining a dictionar whose keys are most common words and values are the indexes
vocab_indexing = {k:v for (v,k) in enumerate(mostCommonWords)}

# Tokenization : spliting the content of each file to list of words 
contentTokenized = []
for content in contentList:
	contentTokenized += [content.split()]

# Vectorization : Converting the words to integres using the most common words
contentVectorized = np.zeros((numOfSamples,BoW_size),dtype=np.int16)
for (row,content) in enumerate(contentTokenized):
	for word in content:
		if word in vocab_indexing:
			word_index = vocab_indexing[word]
			contentVectorized[row,word_index]+=1		

##### Splitting data into train, val, and test set
train_data   	= contentVectorized[:trainLength]
train_label  	= lableList  	   [:trainLength]
val_data  	= contentVectorized[trainLength : trainLength+valLength]
val_label 	= lableList        [trainLength : trainLength+valLength]
test_data    	= contentVectorized[trainLength+valLength:]
test_label   	= lableList        [trainLength+valLength:]

numHam_train 	= train_label.count(0)
numSpam_train 	= train_label.count(1)
numHam_val 	= val_label.count(0)
numSpam_val 	= val_label.count(1)
numHam_test 	= test_label.count(0)
numSpam_test 	= test_label.count(1)

'''
### Ploting how spam and ham distributed on training / val / test sets
width = 0.35
plt.bar(0, numHam_train , width, color='b')
plt.bar(0, numSpam_train, width,  bottom=numHam_train, color='r')

plt.bar(1, numHam_val , width, color='b',label='Ham')
plt.bar(1, numSpam_val, width,  bottom=numHam_val, color='r')

plt.bar(2, numHam_test , width, color='b',label='Ham')
plt.bar(2, numSpam_test, width,  bottom=numHam_test, color='r')
plt.xticks([0,1,2],['Training','Validation','Test'])

plt.ylabel('Number of E-mails')
plt.legend(['Ham','Spam'])
plt.title("Class distribution")
plt.show()
'''

########################################################################
##########     Naive Bayes Classifier       ############################
########################################################################

print("*** Multinomial Naive Bayes Classifer ***")
classifier = MultinomialNB()
classifier.fit(train_data, train_label)

prediction = classifier.predict(test_data) 
test_conf = computeConfMatrix(prediction,test_label)
test_metrics = performanceMetrics(test_conf)

predoction_prob = classifier.predict_proba(test_data)
FPR_NB ,TPR_NB = ROC(predoction_prob[:,1],test_label) 		

print("----Test set----")
print(" ham class accuracy : %1.4f, precision: %1.4f, recall: %1.4f, f1-score : %1.4f" % (test_metrics['acc_ham'],test_metrics['precision_ham'],test_metrics['recall_ham'],test_metrics['f1Score_ham']))
print("spam class accuracy : %1.4f, precision: %1.4f, recall: %1.4f, f1-score : %1.4f" % (test_metrics['acc_spam'],test_metrics['precision_spam'],test_metrics['recall_spam'],test_metrics['f1Score_spam']))
print("----------------")

########################################################################
##########     Decision Tree Classifier     ############################
########################################################################

print("*** Decision Tree Classifier ***")
classifier = DecisionTreeClassifier()			
classifier.fit(train_data, train_label)

prediction = classifier.predict(test_data)
test_conf = computeConfMatrix(prediction,test_label)
test_metrics = performanceMetrics(test_conf)

predoction_prob = classifier.predict_proba(test_data)
FPR_DT ,TPR_DT = ROC(predoction_prob[:,1],test_label) 
print("----Test set----")
print(" ham class accuracy : %1.4f, precision: %1.4f, recall: %1.4f, f1-score : %1.4f" % (test_metrics['acc_ham'],test_metrics['precision_ham'],test_metrics['recall_ham'],test_metrics['f1Score_ham']))
print("spam class accuracy : %1.4f, precision: %1.4f, recall: %1.4f, f1-score : %1.4f" % (test_metrics['acc_spam'],test_metrics['precision_spam'],test_metrics['recall_spam'],test_metrics['f1Score_spam']))
print("----------------")

########################################################################
##########        K-Nearest Neighbors       ############################
########################################################################

print("*** K-Nearest Neighbors Classifer ***")
classifier = KNeighborsClassifier()			
classifier.fit(train_data, train_label)
prediction = classifier.predict(test_data)
test_conf = computeConfMatrix(prediction,test_label)
test_metrics = performanceMetrics(test_conf)

predoction_prob = classifier.predict_proba(test_data)
FPR_KN ,TPR_KN = ROC(predoction_prob[:,1],test_label) 

print("----Test set----")
print(" ham class accuracy : %1.4f, precision: %1.4f, recall: %1.4f, f1-score : %1.4f" % (test_metrics['acc_ham'],test_metrics['precision_ham'],test_metrics['recall_ham'],test_metrics['f1Score_ham']))
print("spam class accuracy : %1.4f, precision: %1.4f, recall: %1.4f, f1-score : %1.4f" % (test_metrics['acc_spam'],test_metrics['precision_spam'],test_metrics['recall_spam'],test_metrics['f1Score_spam']))
print("----------------")


########################################################################
##########  Logistic Regression Classifier  ############################
########################################################################
print("*** Logistic Regression Classifer ***")

# Data Loaders
batchSize = 32
train_loader = EnronBatchLoader(data = torch.Tensor(train_data)	,label = torch.Tensor(train_label)	,batchSize=batchSize	,shuffle=True)
val_loader   = EnronBatchLoader(data = torch.Tensor(val_data)	,label = torch.Tensor(val_label)	,batchSize=batchSize	,shuffle=False)
test_loader  = EnronBatchLoader(data = torch.Tensor(test_data)	,label = torch.Tensor(test_label)	,batchSize=batchSize	,shuffle=False)	

# Classifier

classifier = ClassifierLogisticRegression(batchSize = 32,outputSize = 1,   inputSize = BoW_size, device = 'cpu')
best_spamF1Score = 0
numEpoches_max = 100
epoch = 0
# if perfromance dose not imporve for certain number of consecutive epoches stop the training
numEoches_stopCriteria = 10 
counter_stop = 0

while (epoch < numEpoches_max) and (counter_stop < numEoches_stopCriteria):
	# train 
	classifier.train(train_loader)
	# validation
	_,prediction = classifier.predict(val_loader)
	# confusion matrix
	val_conf = computeConfMatrix(prediction,val_label)
	# performance metrics
	val_metrics = performanceMetrics(val_conf)
	# if performance on val improves then save best model and reset the stop counter
	if val_metrics['f1Score_spam'] > best_spamF1Score:
		best_spamF1Score = val_metrics['f1Score_spam'] 
		counter_stop = 0
		classifier.saveWeights('bestModel_LL.pt')
	else:
		counter_stop += 1
	epoch += 1

# measure the performance of the best model on test set
classifier.loadWeights('bestModel_LL.pt')
predoction_prob, prediction = classifier.predict(test_loader)
test_conf = computeConfMatrix(prediction,test_label)
test_metrics = performanceMetrics(test_conf)
FPR_LR ,TPR_LR = ROC(np.array(predoction_prob),test_label) 


print("----Test set----")
print(" ham class accuracy : %1.4f, precision: %1.4f, recall: %1.4f, f1-score : %1.4f" % (test_metrics['acc_ham'],test_metrics['precision_ham'],test_metrics['recall_ham'],test_metrics['f1Score_ham']))
print("spam class accuracy : %1.4f, precision: %1.4f, recall: %1.4f, f1-score : %1.4f" % (test_metrics['acc_spam'],test_metrics['precision_spam'],test_metrics['recall_spam'],test_metrics['f1Score_spam']))
print("----------------")



########################################################################
##########        Long Short Term Memory    ############################
########################################################################

print("*** Long Short Term Memory Classifer ***")
# input data for lstm is extracted using a larger vocabulary which will then be embedded in lower dimentional space
# as lstm can accept input of different sizes, we will not use bags of words, instead word embedding will be utilized
content_lengths = []
for content in contentList:
	length = len(content.split())
	content_lengths += [length] 
maxLength = max(content_lengths)


# tokenization : split each content to a list of words
contentTokenized = [] # list of contents splitted into list of words
for content in contentList:
	contentTokenized += [content.split()]	


vocabSize = 4000
mostCommonWords = wordSorted[:vocabSize-2]
vocab_indexing = {k:v+2 for (v,k) in enumerate(mostCommonWords)} # 0 : pad, 1: unknown(not in vocab)


# indexing word in tokenized content

contentIndexed = [] # list of content:list of indexes	
for content in contentTokenized:
	c_indexed = []
	for word in content:
		word_index = vocab_indexing.get(word,1)
		c_indexed += [word_index]
	contentIndexed += [c_indexed]

# now padding zeros data tensor will have n_samples x maxLength size
content_tensor = torch.zeros((numOfSamples,maxLength)).long()

for index in range(numOfSamples):
	contentLength = content_lengths[index]
	content_tensor[index,:contentLength] = torch.LongTensor(contentIndexed[index])

content_lengths = torch.LongTensor(content_lengths)

print("maximum sequence length:%d" % maxLength)



# spliting train / val / test
#lableList = torch.Tensor(lableList)

train_data   = content_tensor[:trainLength]
train_label  =       lableList[:trainLength]
train_lengths= content_lengths[:trainLength]

val_data  = content_tensor[trainLength : trainLength+valLength]
val_label = lableList      [trainLength : trainLength+valLength]
val_lengths= content_lengths[trainLength : trainLength+valLength]

test_data  = content_tensor[trainLength+valLength:]
test_label = lableList      [trainLength+valLength:]
test_lengths= content_lengths[trainLength+valLength:]	

# LSTM

# Loaders

batchSize = 256
train_loader = EnronBatchLoader(data=train_data	,label=torch.Tensor(train_label),seqLengths=train_lengths	,batchSize=batchSize,shuffle=True	,LSTM=True)
val_loader   = EnronBatchLoader(data=val_data	,label=torch.Tensor(val_label)	,seqLengths=val_lengths		,batchSize=batchSize,shuffle=False	,LSTM=True)
test_loader  = EnronBatchLoader(data=test_data,	label=torch.Tensor(test_label)	,seqLengths=test_lengths	,batchSize=batchSize,shuffle=False	,LSTM=True)


# classfier

classifier = ClassifierLSTM(batchSize = batchSize,train_data = train_data,val_data = val_data,test_data = test_data,\
		train_label = train_label,val_label = val_label,test_label=test_label,\
		train_lengths = train_lengths, val_lengths = val_lengths, test_lengths = test_lengths,\
		outputSize = 1, numLayers = 2, hiddenSize = 64, embedSize = 512, vocabSize = vocabSize,\
		device = 'cpu')

best_spamF1Score = 0
numEpoches_max = 100
epoch = 0
# if perfromance dose not imporve for certain number of consecutive epoches stop the training
numEoches_stopCriteria = 10 
counter_stop = 0

while (epoch < numEpoches_max) and (counter_stop < numEoches_stopCriteria):
	# train 
	prediction = classifier.train(train_loader)
	# validation
	_,prediction,labels = classifier.predict(val_loader)
	# confusion matrix
	val_conf = computeConfMatrix(prediction,labels)
	# performance metrics
	val_metrics = performanceMetrics(val_conf)
	# if performance on val improves then save best model and reset the stop counter
	if val_metrics['f1Score_spam'] > best_spamF1Score:
		best_spamF1Score = val_metrics['f1Score_spam'] 
		counter_stop = 0
		classifier.saveWeights('bestModel_LSTM.pt')
	else:
		counter_stop += 1
	epoch += 1

# measure the performance of the best model on test set
classifier.loadWeights('bestModel_LSTM.pt')
predoction_prob,prediction,labels  = classifier.predict(test_loader)
test_conf = computeConfMatrix(prediction,labels)
test_metrics = performanceMetrics(test_conf)
FPR_LSTM ,TPR_LSTM = ROC(np.array(predoction_prob),labels) 

print("----Test set----")
print(" ham class accuracy : %1.4f, precision: %1.4f, recall: %1.4f, f1-score : %1.4f" % (test_metrics['acc_ham'],test_metrics['precision_ham'],test_metrics['recall_ham'],test_metrics['f1Score_ham']))
print("spam class accuracy : %1.4f, precision: %1.4f, recall: %1.4f, f1-score : %1.4f" % (test_metrics['acc_spam'],test_metrics['precision_spam'],test_metrics['recall_spam'],test_metrics['f1Score_spam']))
print("----------------")



 # Plotting ROC curve #
plt.plot(FPR_NB,TPR_NB,label='Multinomial Naive Bayes',linewidth = 2)
plt.plot(FPR_DT,TPR_DT,label='Decision Tree',linewidth = 2)
plt.plot(FPR_KN,TPR_KN,label='K-Nearest Neighbors',linewidth = 2)
plt.plot(FPR_LR,TPR_LR,label='Logistic Regression',linewidth = 2)
plt.plot(FPR_LSTM,TPR_LSTM,label='LSTM',linewidth = 2)
plt.legend(loc='lower right')
plt.ylabel("True Positive Rate")
plt.xlabel("False Positive Rate")
plt.xlim([-0.01,0.4])
plt.ylim([0.6,1.01])
plt.show()






















